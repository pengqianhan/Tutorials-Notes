
# Transformer resources

- D2L offers an excellent chapter on the Transformer [11.7](https://d2l.ai/chapter_attention-mechanisms-and-transformers/transformer.html).
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) provides numerous illustrations to aid in understanding the Transformer.
- [Illustrated Guide to Transformers: Step-by-Step Explanation](https://towardsdatascience.com/illustrated-guide-to-transformers-step-by-step-explanation-f74876522bc0)
- [Self-Attention and Transformer](https://luweikxy.gitbook.io/machine-learning-notes/self-attention-and-transformer)
- [The Annotated Transformer](https://nlp.seas.harvard.edu/annotated-transformer/) offers a detailed introduction to the algorithm using code from the original paper "Attention is All You Need" by Transformer, explaining the training and inference processes.
- [A Walkthrough of Transformer Architecture Code](https://github.com/markriedl/transformer-walkthrough/tree/main)
- [The Transformer Family Version 2.0](https://towardsdatascience.com/transformer-networks-a-mathematical-explanation-why-scaling-the-dot-products-leads-to-more-stable-414f87391500)
- Embrace the Hugging Face [Transformer library](https://huggingface.co/docs/transformers/en/installation) for rapidly designing your model.

